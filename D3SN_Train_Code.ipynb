{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fbd0d4f-a159-472b-a4f0-95ce12d0b32e",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "339ac234-72f6-4d96-b499-ae7a89deb52f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T01:59:22.987048Z",
     "iopub.status.busy": "2023-04-29T01:59:22.986358Z",
     "iopub.status.idle": "2023-04-29T01:59:23.800791Z",
     "shell.execute_reply": "2023-04-29T01:59:23.800085Z",
     "shell.execute_reply.started": "2023-04-29T01:59:22.986980Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#*******________________________Code for Training DSD_Net______________________________*******\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os, glob\n",
    "import random, csv\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#import visdom\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79962d49-698b-4e0b-861f-5729735511ae",
   "metadata": {},
   "source": [
    "#### Custom Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "737c602e-ee04-474e-b702-eb7d32cf8f41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T01:59:23.805776Z",
     "iopub.status.busy": "2023-04-29T01:59:23.805410Z",
     "iopub.status.idle": "2023-04-29T01:59:24.193808Z",
     "shell.execute_reply": "2023-04-29T01:59:24.193277Z",
     "shell.execute_reply.started": "2023-04-29T01:59:23.805754Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import utils.utils_image as util\n",
    "\n",
    "\n",
    "class DatasetSR(data.Dataset):\n",
    "    \n",
    "\n",
    "    def __init__(self):\n",
    "        super(DatasetSR, self).__init__()\n",
    "        self.n_channels = 1\n",
    "        self.sf = 1\n",
    "        self.patch_size = 128\n",
    "        self.L_size = self.patch_size // self.sf\n",
    "\n",
    "        # ------------------------------------\n",
    "        # get paths of L/H\n",
    "        # ------------------------------------\n",
    "        self.paths_H = util.get_image_paths('/notebooks/JPEG_HR_Gray/DIV2K_train_HR_Grayscale')  #The Path of Ground Truth Images\n",
    "        self.paths_L = util.get_image_paths('/notebooks/JPEG_LR_Gray/JPEG_Grayscale/JPEG_05')    #The path of LR Images \n",
    "        '''\n",
    "        assert self.paths_H, 'Error: H path is empty.'\n",
    "        if self.paths_L and self.paths_H:\n",
    "            assert len(self.paths_L) == len(self.paths_H), 'L/H mismatch - {}, {}.'.format(len(self.paths_L), len(self.paths_H))\n",
    "        '''\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        H_path = None\n",
    "        # ------------------------------------\n",
    "        # get H image\n",
    "        # ------------------------------------\n",
    "        L_path = self.paths_L[index]\n",
    "        img_L = util.imread_uint(L_path, self.n_channels)\n",
    "        img_L = util.uint2single(img_L)\n",
    "\n",
    "        # ------------------------------------\n",
    "        # modcrop\n",
    "        # ------------------------------------\n",
    "        \n",
    "\n",
    "        # ------------------------------------\n",
    "        # get L image\n",
    "        # ------------------------------------\n",
    "        if self.paths_H:\n",
    "            # --------------------------------\n",
    "            # directly load L image\n",
    "            # --------------------------------\n",
    "            H_path = self.paths_H[index % 800]\n",
    "            img_H = util.imread_uint(H_path, self.n_channels)\n",
    "            img_H = util.uint2single(img_H)\n",
    "            img_H = util.modcrop(img_H, self.sf)\n",
    "        else:\n",
    "            # --------------------------------\n",
    "            # sythesize L image via matlab's bicubic\n",
    "            # --------------------------------\n",
    "            H, W = img_H.shape[:2]\n",
    "            img_L = util.imresize_np(img_H, 1 / self.sf, True)\n",
    "\n",
    "        # ------------------------------------\n",
    "        # if train, get L/H patch pair\n",
    "        # ------------------------------------\n",
    "\n",
    "        H, W, C = img_L.shape\n",
    "\n",
    "        # --------------------------------\n",
    "        # randomly crop the L patch\n",
    "        # --------------------------------\n",
    "        rnd_h = random.randint(0, max(0, H - self.L_size))\n",
    "        rnd_w = random.randint(0, max(0, W - self.L_size))\n",
    "        img_L = img_L[rnd_h:rnd_h + self.L_size, rnd_w:rnd_w + self.L_size]\n",
    "\n",
    "        # --------------------------------\n",
    "        # crop corresponding H patch\n",
    "        # --------------------------------\n",
    "        rnd_h_H, rnd_w_H = int(rnd_h * self.sf), int(rnd_w * self.sf)\n",
    "        img_H = img_H[rnd_h_H:rnd_h_H + self.patch_size, rnd_w_H:rnd_w_H + self.patch_size]\n",
    "\n",
    "        # --------------------------------\n",
    "        # augmentation - flip and/or rotate\n",
    "        # --------------------------------\n",
    "        \n",
    "        mode = random.randint(0, 7)\n",
    "        img_L, img_H = util.augment_img(img_L, mode=mode), util.augment_img(img_H, mode=mode)\n",
    "        \n",
    "        # ------------------------------------\n",
    "        # L/H pairs, HWC to CHW, numpy to tensor\n",
    "        # ------------------------------------\n",
    "        img_H, img_L = util.single2tensor3(img_H), util.single2tensor3(img_L)\n",
    "\n",
    "        if L_path is None:\n",
    "            L_path = H_path\n",
    "\n",
    "        return {'L': img_L, 'H': img_H, 'L_path': L_path, 'H_path': H_path}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths_L)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f431af1e-1703-460c-8e3a-bfd40046ca85",
   "metadata": {},
   "source": [
    "#### Create Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51bf2057-1163-4888-9401-5dba6dc603ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T01:59:24.194790Z",
     "iopub.status.busy": "2023-04-29T01:59:24.194556Z",
     "iopub.status.idle": "2023-04-29T01:59:24.212918Z",
     "shell.execute_reply": "2023-04-29T01:59:24.212450Z",
     "shell.execute_reply.started": "2023-04-29T01:59:24.194775Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = DatasetSR()\n",
    "#train_sampler = DistributedSampler(train_set, shuffle=True, drop_last=True)\n",
    "train_loader = DataLoader(train_set,\n",
    "                          batch_size=8,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers = 4,\n",
    "                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7dcf2bf-7914-482d-87bc-d63e593893ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T01:59:24.214239Z",
     "iopub.status.busy": "2023-04-29T01:59:24.214065Z",
     "iopub.status.idle": "2023-04-29T01:59:24.220847Z",
     "shell.execute_reply": "2023-04-29T01:59:24.220365Z",
     "shell.execute_reply.started": "2023-04-29T01:59:24.214225Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom matplotlib import pyplot as plt\\narr = x[1].permute(1,2,0)\\n#arr = torch.Tensor.numpy(x[1])\\nprint(arr.shape)\\nplt.imshow(arr)\\n\\nplt.imshow(x[1].permute(1, 2, 0),cmap='gray')\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from matplotlib import pyplot as plt\n",
    "arr = x[1].permute(1,2,0)\n",
    "#arr = torch.Tensor.numpy(x[1])\n",
    "print(arr.shape)\n",
    "plt.imshow(arr)\n",
    "\n",
    "plt.imshow(x[1].permute(1, 2, 0),cmap='gray')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca88c022-f404-4c56-8184-3e8263058584",
   "metadata": {},
   "source": [
    "### DCT Submodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90647cbb-6767-4992-b19d-ea033567c540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T01:59:24.221932Z",
     "iopub.status.busy": "2023-04-29T01:59:24.221776Z",
     "iopub.status.idle": "2023-04-29T01:59:24.229981Z",
     "shell.execute_reply": "2023-04-29T01:59:24.229476Z",
     "shell.execute_reply.started": "2023-04-29T01:59:24.221918Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#import tensorflow as tf\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "import torchvision\n",
    "\n",
    "class LWAB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LWAB, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 64, out_channels= 256, kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels= 64, kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n",
    "            nn.PReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_1 = self.block(x)\n",
    "        out_2 = self.block(out_1)\n",
    "        \n",
    "        return x + out_1 + out_2\n",
    "\n",
    "class DCT_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DCT_Net, self).__init__()\n",
    "        #Patch_Extraction is the 1st layer of DCT Network with Channels of 64 and filters of 8 X 8\n",
    "        self.Patch_Extraction = nn.Sequential(nn.Conv2d(in_channels= 1, out_channels= 64, kernel_size=(8,8), stride=(1,1), padding=(3,3)),\n",
    "                                      nn.ReLU()\n",
    "                                      )\n",
    "        #DCT and IDCT layers Have Channel size 64 and filter size 1 X 1\n",
    "        self.DCT = nn.Sequential(nn.Conv2d(in_channels= 64, out_channels= 64, kernel_size=(1,1), stride=(1,1), padding=(0,0)),\n",
    "                                      nn.ReLU()\n",
    "                                      )\n",
    "        \n",
    "        self.IDCT = nn.Sequential(nn.Conv2d(in_channels= 64, out_channels= 64, kernel_size=(1,1), stride=(1,1), padding=(0,0)),\n",
    "                                      nn.ReLU()\n",
    "                                      )\n",
    "        # The Weights of DCT and IDCT are not updated during the training process\n",
    "        self.DCT.requires_grad_(False)    \n",
    "        self.IDCT.requires_grad_(False)\n",
    "        \n",
    "        #LWAB_body contains the code for implementing LWAB. 3 LWAB Blocks are used in D3SN\n",
    "        \n",
    "        LWAB_body = [LWAB() for _ in range(3)]       \n",
    "        self.LWAB_body = nn.Sequential(*LWAB_body)\n",
    "        \n",
    "        #Patch_Reconstruction Outputs the Final Output of DCT Branch\n",
    "        \n",
    "        self.Patch_Reconstruction = nn.Sequential(nn.Conv2d(in_channels= 64, out_channels= 1, kernel_size=(8,8), stride=(1,1), padding=(4,4)),\n",
    "                                      )\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.Patch_Extraction(x)                                #Extract the image Patch   \n",
    "        #print('E Layer: ', output.shape)\n",
    "        output_DCT = self.DCT(output)                                    #Pass Through DCT layer\n",
    "        output_LWARG = self.LWAB_body(output_DCT)                        #Pass Through LWARGs\n",
    "        #print('LWARGs: ', output_LWARG.shape)\n",
    "        output_final = output_LWARG + output_DCT                         #Residual Connection: LWARGs Output + DCT\n",
    "        #print('LWARG_Res: ', output_final.shape)\n",
    "        output_IDCT = self.IDCT(output_final)                            #Pass Through IDCT layer\n",
    "        #print('IDCT: ', output_IDCT.shape)\n",
    "        output_image_1 = self.Patch_Reconstruction(output_IDCT)          #Final output of DCT Branch\n",
    "         \n",
    "        \n",
    "        #print(output_image_1.shape)\n",
    "        \n",
    "        \n",
    "       \n",
    "        return output_image_1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332f66cf-6cee-4bdd-bfc0-c7747b61e725",
   "metadata": {},
   "source": [
    "### DPD Submodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "939f8009-7c1a-47ea-97b0-d4560c5f4fc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T01:59:24.231052Z",
     "iopub.status.busy": "2023-04-29T01:59:24.230900Z",
     "iopub.status.idle": "2023-04-29T01:59:24.242349Z",
     "shell.execute_reply": "2023-04-29T01:59:24.241871Z",
     "shell.execute_reply.started": "2023-04-29T01:59:24.231038Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Up_Sample(nn.Module):\n",
    "    def __init__(self, scale, act=False):\n",
    "        super(Up_Sample, self).__init__()\n",
    "        modules = []\n",
    "        modules.append(nn.PixelShuffle(scale))\n",
    "        self.body = nn.Sequential(*modules)\n",
    "    def forward(self, x):\n",
    "        x = self.body(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class make_dense(nn.Module):\n",
    "  def __init__(self, nChannels, growthRate, kernel_size=3):\n",
    "    super(make_dense, self).__init__()\n",
    "    self.conv = nn.Sequential(nn.Conv2d(in_channels= nChannels, out_channels= growthRate, kernel_size=3, stride=(1,1), padding=(1,1),bias = True),\n",
    "                                      nn.PReLU()\n",
    "                                      )\n",
    "  def forward(self, x):\n",
    "    out = self.conv(x)\n",
    "    out = torch.cat((x, out), 1)\n",
    "    return out\n",
    "\n",
    "# Residual dense block (RDB) architecture\n",
    "class RDB(nn.Module):\n",
    "  def __init__(self, nChannels, nDenselayer, growthRate):\n",
    "    super(RDB, self).__init__()\n",
    "    nChannels_ = nChannels\n",
    "    modules = []\n",
    "    for i in range(nDenselayer):    \n",
    "        modules.append(make_dense(nChannels_, growthRate))\n",
    "        nChannels_ += growthRate \n",
    "    self.dense_layers = nn.Sequential(*modules)    \n",
    "    self.conv_1x1 = nn.Conv2d(nChannels_, nChannels, kernel_size=1, padding=0, bias=False)\n",
    "  def forward(self, x):\n",
    "    out = self.dense_layers(x)\n",
    "    out = self.conv_1x1(out)\n",
    "    out = out + x\n",
    "    return out\n",
    "class DPD_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DPD_Net, self).__init__()\n",
    "        #Patch_Extraction is the 1st layer of DPD_Net. 1 X 1 Convolution Performed on the input image followed by a PRelu Layer\n",
    "        self.Patch_Extraction = nn.Sequential(nn.Conv2d(in_channels= 1, out_channels= 64, kernel_size=(1,1), stride=(1,1), padding=(0,0)),\n",
    "                                      nn.PReLU()\n",
    "                                      )\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.AWDRU_64X64 = RDB(64,3,64)   \n",
    "        \n",
    "        \n",
    "        self.AWDRU_128X128 = RDB(128, 3, 128)\n",
    "        \n",
    "        \n",
    "        self.AWDRU_256X256 = RDB(256, 3, 256)\n",
    "        \n",
    "        \n",
    "        #Up-sampling Module. Upsamples by a scale of 2\n",
    "        self.upsample = Up_Sample(2)\n",
    "        \n",
    "\n",
    "        \n",
    "        #Downsampling Module\n",
    "        self.Down_Sample_64_128 = nn.Sequential(nn.Conv2d(in_channels= 64, out_channels= 128, kernel_size=(1,1), stride=(2,2), padding=(0,0)),\n",
    "                                      nn.PReLU()\n",
    "                                      )\n",
    "        \n",
    "        self.Down_Sample_128_256 = nn.Sequential(nn.Conv2d(in_channels= 128, out_channels= 256, kernel_size=(1,1), stride=(2,2), padding=(0,0)),\n",
    "                                      nn.PReLU()\n",
    "                                      )\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.Patch_Reconstruction = nn.Sequential(nn.Conv2d(in_channels= 128, out_channels= 1, kernel_size=(1,1), stride=(1,1), padding=(0,0)),\n",
    "                                                  nn.PReLU()\n",
    "                                      )\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        feature = self.Patch_Extraction(x)\n",
    "        #print(feature.shape)\n",
    "        AWDRU_1 = self.AWDRU_64X64(feature)\n",
    "        #print('k')\n",
    "        AWDRU_2 = self.AWDRU_64X64(AWDRU_1)\n",
    "        AWDRU_3 = self.AWDRU_64X64(AWDRU_2)\n",
    "        Down_1 = self.Down_Sample_64_128(AWDRU_3)\n",
    "        AWDRU_4 = self.AWDRU_128X128(Down_1)\n",
    "        AWDRU_5 = self.AWDRU_128X128(AWDRU_4)\n",
    "        AWDRU_6 = self.AWDRU_128X128(AWDRU_5)\n",
    "        Down_2 = self.Down_Sample_128_256(AWDRU_6)\n",
    "        AWDRU_7 = self.AWDRU_256X256(Down_2)\n",
    "        AWDRU_8 = self.AWDRU_256X256(AWDRU_7)\n",
    "        AWDRU_9 = self.AWDRU_256X256(AWDRU_8)\n",
    "        Concat_1 = torch.cat((AWDRU_7, AWDRU_9), 1)\n",
    "        #print('COncat_1',Concat_1.shape)\n",
    "        Up_1 = self.upsample(Concat_1)\n",
    "        #print('Up1: ',Up_1.shape)\n",
    "        AWDRU_10 = self.AWDRU_128X128(Up_1)\n",
    "        Concat_2 = torch.cat((AWDRU_10, AWDRU_6), 1)\n",
    "        AWDRU_11 = self.AWDRU_256X256(Concat_2)\n",
    "        AWDRU_12 = self.AWDRU_256X256(AWDRU_11)\n",
    "        Up_2 = self.upsample(AWDRU_12)\n",
    "        AWDRU_13 = self.AWDRU_64X64(Up_2)\n",
    "        Concat_3 = torch.cat((AWDRU_3, AWDRU_13), 1)\n",
    "        AWDRU_14 = self.AWDRU_128X128(Concat_3)\n",
    "        AWDRU_15 = self.AWDRU_128X128(AWDRU_14)\n",
    "        out = self.Patch_Reconstruction(AWDRU_15)\n",
    "        final = out + x\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "       \n",
    "        return final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b640ae2-e217-4ea8-99de-65f80aec6aab",
   "metadata": {},
   "source": [
    "### D3SN Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d616b855-a509-47ea-b6eb-c41b00f8977d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T01:59:24.243052Z",
     "iopub.status.busy": "2023-04-29T01:59:24.242903Z",
     "iopub.status.idle": "2023-04-29T01:59:24.247181Z",
     "shell.execute_reply": "2023-04-29T01:59:24.246677Z",
     "shell.execute_reply.started": "2023-04-29T01:59:24.243039Z"
    }
   },
   "outputs": [],
   "source": [
    "class D3SN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(D3SN, self).__init__()\n",
    "        self.DCT = DCT_Net()\n",
    "        self.DPD = DPD_Net()\n",
    "        \n",
    "        self.Patch_Reconstruction = nn.Sequential(nn.Conv2d(in_channels= 2, out_channels= 1, kernel_size=(1,1), stride=(1,1), padding=(0,0),bias = False)\n",
    "                                      )      \n",
    "        \n",
    "    def forward(self, x):\n",
    "        DCT = self.DCT(x)\n",
    "        DPD = self.DPD(x)\n",
    "        Concat = torch.cat((DCT,DPD),1)\n",
    "        final = self.Patch_Reconstruction(Concat)\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "       \n",
    "        return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4b036d0-2074-4b61-99fc-6fcfc8316916",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T01:59:24.247900Z",
     "iopub.status.busy": "2023-04-29T01:59:24.247758Z",
     "iopub.status.idle": "2023-04-29T01:59:25.554723Z",
     "shell.execute_reply": "2023-04-29T01:59:25.554173Z",
     "shell.execute_reply.started": "2023-04-29T01:59:24.247887Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D3SN(\n",
      "  (DCT): DCT_Net(\n",
      "    (Patch_Extraction): Sequential(\n",
      "      (0): Conv2d(1, 64, kernel_size=(8, 8), stride=(1, 1), padding=(3, 3))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (DCT): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (IDCT): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (LWAB_body): Sequential(\n",
      "      (0): LWAB(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): PReLU(num_parameters=1)\n",
      "          (2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): PReLU(num_parameters=1)\n",
      "        )\n",
      "      )\n",
      "      (1): LWAB(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): PReLU(num_parameters=1)\n",
      "          (2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): PReLU(num_parameters=1)\n",
      "        )\n",
      "      )\n",
      "      (2): LWAB(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): PReLU(num_parameters=1)\n",
      "          (2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (3): PReLU(num_parameters=1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (Patch_Reconstruction): Sequential(\n",
      "      (0): Conv2d(64, 1, kernel_size=(8, 8), stride=(1, 1), padding=(4, 4))\n",
      "    )\n",
      "  )\n",
      "  (DPD): DPD_Net(\n",
      "    (Patch_Extraction): Sequential(\n",
      "      (0): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (AWDRU_64X64): RDB(\n",
      "      (dense_layers): Sequential(\n",
      "        (0): make_dense(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): PReLU(num_parameters=1)\n",
      "          )\n",
      "        )\n",
      "        (1): make_dense(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): PReLU(num_parameters=1)\n",
      "          )\n",
      "        )\n",
      "        (2): make_dense(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): PReLU(num_parameters=1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (AWDRU_128X128): RDB(\n",
      "      (dense_layers): Sequential(\n",
      "        (0): make_dense(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): PReLU(num_parameters=1)\n",
      "          )\n",
      "        )\n",
      "        (1): make_dense(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): PReLU(num_parameters=1)\n",
      "          )\n",
      "        )\n",
      "        (2): make_dense(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): PReLU(num_parameters=1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv_1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (AWDRU_256X256): RDB(\n",
      "      (dense_layers): Sequential(\n",
      "        (0): make_dense(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): PReLU(num_parameters=1)\n",
      "          )\n",
      "        )\n",
      "        (1): make_dense(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): PReLU(num_parameters=1)\n",
      "          )\n",
      "        )\n",
      "        (2): make_dense(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): PReLU(num_parameters=1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (conv_1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (upsample): Up_Sample(\n",
      "      (body): Sequential(\n",
      "        (0): PixelShuffle(upscale_factor=2)\n",
      "      )\n",
      "    )\n",
      "    (Down_Sample_64_128): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "      (1): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (Down_Sample_128_256): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "      (1): PReLU(num_parameters=1)\n",
      "    )\n",
      "    (Patch_Reconstruction): Sequential(\n",
      "      (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): PReLU(num_parameters=1)\n",
      "    )\n",
      "  )\n",
      "  (Patch_Reconstruction): Sequential(\n",
      "    (0): Conv2d(2, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = D3SN()\n",
    "model.to(device)\n",
    "co_ef = 1e-3\n",
    "error = nn.L1Loss()\n",
    "\n",
    "learning_rate = 1e-4 \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,betas=(0.9, 0.999), eps=1e-08) # Code to use the Adam Optimizer\n",
    "scheduler = MultiStepLR(optimizer, milestones=[10 * 100 ,20 * 100 , 30 * 100, 40 * 100], gamma=0.5) #milestones=[Intended Epoch * Batch Size]\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcf358a3-8cfb-40c6-8213-0462a649e5a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T01:59:25.555637Z",
     "iopub.status.busy": "2023-04-29T01:59:25.555451Z",
     "iopub.status.idle": "2023-04-29T01:59:25.592545Z",
     "shell.execute_reply": "2023-04-29T01:59:25.592073Z",
     "shell.execute_reply.started": "2023-04-29T01:59:25.555637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Load IAM Branch_1 Optimizer Checkpoint\\nsaved_state_dict = torch.load('/notebooks/JPEG_Gray_IDPD_Files/models_1_channel/Optimizer300.pth')\\noptimizer.load_state_dict(saved_state_dict)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Template for loading presaved check points for training.\n",
    "'''\n",
    "#IAM_3 = IAM_Net()\n",
    "saved_state_dict = torch.load('/notebooks/D3SN_Files/models_JPEG_10/D3SN_JPEG_10_5000.pth')\n",
    "model.load_state_dict(saved_state_dict)\n",
    "#IAM_3 = IAM_3.to(device)\n",
    "model.train()\n",
    "\n",
    "\n",
    "#Load IAM Branch_1 Optimizer Checkpoint\n",
    "saved_state_dict = torch.load('/notebooks/JPEG_Gray_IDPD_Files/models_1_channel/Optimizer300.pth')\n",
    "optimizer.load_state_dict(saved_state_dict)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771474a1-3562-408c-8df8-95fd71a03b29",
   "metadata": {},
   "source": [
    "#### Create Log File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b06066e-ade2-4316-86a7-82d453ff4ae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T01:59:25.594132Z",
     "iopub.status.busy": "2023-04-29T01:59:25.593929Z",
     "iopub.status.idle": "2023-04-29T01:59:25.598116Z",
     "shell.execute_reply": "2023-04-29T01:59:25.597461Z",
     "shell.execute_reply.started": "2023-04-29T01:59:25.594132Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "        level=logging.DEBUG,\n",
    "        format=\"%(asctime)s %(levelname)s %(message)s\",\n",
    "        datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "        filename=\"/notebooks/D3SN_Files/logs/train_D3SN_JPEG_05.log\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9639669b-76fa-4035-937e-f4d72c512468",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-29T01:59:25.599048Z",
     "iopub.status.busy": "2023-04-29T01:59:25.598867Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39892ed180144599a9b5d3e268ed974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07d7f9dc66a4534ba81dfe4babda30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f7e52379f64a889b5d335bd8d8b64f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b6dd9b6815481081bb48fc0dd466c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3afa69afda974dbeb259d9d92a94c0f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0cb458d00247e98701e49ef6d78db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2777ebf1b36847de96be6ca904f2317c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0532d7f88bf543ccb2c83801fb134101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c8281d96a745cfbf3e965b3f1ba226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013157954f5a4abd82ac61394d91c9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de64f738ce11476481f077e9c922a90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5012a81c98fd4ffd9737c59b028fafce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653278bc8ab644bda7ca0b8166cfa9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c813fa98246940c5a7670883ddeb9f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6b7221800f4f36b6417a853ff4aca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ecca713c2934760bf9a6eca9458e5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04fb1b4a8db14605a01fbd2618c39824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4311ede1f58a42309fbf32c3b63ed478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0d5fddc81843a7ba0d9f47cec431e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ace0aa09f6b4d9f95da8fa530e24b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f671e0efdc42cf941fdf6f7cca1d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ab74edea1f4e5d8b4ccdd8c473e8ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9915265dda64e36abb2cf260f355782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5befcf5a4ab9447896dc297a90a6243e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3699033d603049c8ac859b066b96be9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf42d9561984801b56f94af083dde1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6286cd7774849da816d32a1eb764af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ba5f3d88284436819abfb94f5fb838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5b7f2c7836489baecdda4f41aa9954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7450a3dc0e64cbfb4cfc3e503cda3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eedd00e77c54697859e8bfe5d2c8183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9fa36375e4649edb7bfd24163577830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362524254020459099e7f0b0f919f069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728daa74bbb14c1fa64433cfbf213f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af307ad1746942ca892212f1ee8b8e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ffb8cd23534af6a34e47c9e2282304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d32e6c5ef540cfa614373745c1ca84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450fc8b6c4684c40b9d22db7c56bc507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02a503cb55449d5aeb1e5a6c7cbc8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c44ff59d8814898a17045bac00d3d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79cca109f4e8418eba93526bdfd70c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530efa3b22514df38da131cd96e2b648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560aae47e5ff4e5a80822f12fbde9092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be8e7de98ff4aef912689284f174268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e9d78d047440dd9bb92a6e7c680ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e3d20ea4b94908946166670420349c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bc3427cade48ab980dbe0db7dab104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3927580015c3419eba207bd91698584e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130ad99242d64eb7842a1769d6cc030e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9c5fa323014322bb82e6e6f4d25424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc3e0e64e2f4e598ace69db47b1a281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "num_epochs = 4000\n",
    "count = 0 * 450\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.train()\n",
    "\n",
    "\n",
    "for epoch in range(1,num_epochs): \n",
    "    for idx, train_data in tqdm(enumerate(train_loader)):\n",
    "        labels = []\n",
    "        L = train_data['L'].to(device)\n",
    "        H = train_data['H'].to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        output = model(L)\n",
    "        \n",
    "        \n",
    "\n",
    "        loss = error(output, H)\n",
    "\n",
    "        # Initializing a gradient as 0 so there is no mixing of gradient among the batches\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "        #Propagating the error backward\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizing the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        count += 1\n",
    "\n",
    "    if (count % 100 == 0):\n",
    "        logging.info(\"Iteration: {}, Loss: {}%, epoch: {}, Learning Rate: {}\".format(count, loss.data,epoch, scheduler.get_last_lr()))\n",
    "        #scheduler.get_last_lr(), Learning Rate: {},\n",
    "    if (count % 1000 == 0 and epoch != 0) or epoch ==3999 :\n",
    "        torch.save(model.state_dict(), os.path.join(\"/notebooks/D3SN_Files/models_JPEG_05\", 'D3SN_JPEG_05_' + str(count) + '.pth'))\n",
    "        torch.save(optimizer.state_dict(), os.path.join(\"/notebooks/D3SN_Files/models_JPEG_05\", 'Optimizer_' + str(count) + '.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
